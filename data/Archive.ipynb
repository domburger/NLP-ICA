{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code Archive NLP ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### Only using praw to gather the latest 1000 posts\n",
    "for submission in reddit.subreddit('ethereum').new(limit=None):\n",
    "    raw_data = raw_data.append({\n",
    "        \"title\":submission.title,\n",
    "        \"text\":submission.selftext,\n",
    "        \"score\":submission.score,\n",
    "        \"time\":pd.to_datetime(submission.created, unit=\"s\"),\n",
    "        \"upvote_ratio\":submission.upvote_ratio\n",
    "    }, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Preprocess\n",
    "tokens = []\n",
    "for text in raw_data[\"text\"]:\n",
    "    text = text.lower()\n",
    "    text = ''.join(ch for ch in text if ch not in string.punctuation)\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = [t for t in text if t not in stop_words]\n",
    "    tokens.append(text)\n",
    "\n",
    "raw_data[\"text\"] = tokens\n",
    "\n",
    "tokens = []\n",
    "for text in raw_data[\"title\"]:\n",
    "    text = text.lower()\n",
    "    text = ''.join(ch for ch in text if ch not in string.punctuation)\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = [t for t in text if t not in stop_words]\n",
    "    tokens.append(text)\n",
    "\n",
    "raw_data[\"title\"] = tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use requests package to gather data!\n",
    "\n",
    "import requests\n",
    "\n",
    "#Authentication\n",
    "auth = requests.auth.HTTPBasicAuth(\"kY_y2GGoj9wIVxupLMPbJg\", \"7tTfZujRWd_oVqE0CZJWntY7IzcKWw\")\n",
    "#Login\n",
    "data = {\"grant_type\": \"password\",\n",
    "        \"username\": \"Boegun\", #Make this an input\n",
    "        \"password\": \"Bezaza12\"} #Make this an input\n",
    "headers = {\"User-Agent\": \"ICATopic/0.0.1\"}\n",
    "res = requests.post(\"https://www.reddit.com/api/v1/access_token\",\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "TOKEN = res.json()[\"access_token\"]\n",
    "headers = {**headers, **{\"Authorization\": f\"bearer {TOKEN}\"}}\n",
    "requests.get(\"https://oautch.reddit.com/api/v1/me\", headers=headers)\n",
    "\n",
    "#Request data, Pulling data from subbreddit \"ethereum\" with search query \"the merge\"\n",
    "res = requests.get(\"https://oauth.reddit.com/r/ethereum/search/?q=the%20merge&restrict_sr=1&sr_nsfw=\", headers=headers)\n",
    "\n",
    "#Build a dataframe for analysis\n",
    "df = pd.DataFrame() #initialize dataframe\n",
    "for post in res.json()[\"data\"][\"children\"]:\n",
    "    #append relevant attributes to dataframe\n",
    "    df = df.append({\n",
    "        #\"subreddit\": post[\"data\"][\"subreddit\"],\n",
    "        \"title\": post[\"data\"][\"title\"],\n",
    "        \"selftext\": post[\"data\"][\"selftext\"],\n",
    "        \"upvote_ratio\": post[\"data\"][\"upvote_ratio\"],\n",
    "        #\"ups\": post[\"data\"][\"ups\"], #Always equal score??\n",
    "        #\"downs\": post[\"data\"][\"downs\"], #Always 0???\n",
    "        \"score\": post[\"data\"][\"score\"],\n",
    "        \"time\":post[\"data\"][\"created\"]\n",
    "    },\n",
    "    ignore_index=True\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#raw_data = raw_data[~raw_data['text'].isin(['[removed]', '[deleted]']).dropna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}